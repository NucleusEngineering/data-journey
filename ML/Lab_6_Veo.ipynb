{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628bb0c7-dad9-4d32-954f-275f6c64380b",
   "metadata": {},
   "source": [
    "# **LAB_6 Veo2 for text-to-video**\n",
    "\n",
    "\n",
    "Are your users receiving your messages but still not returning to your game? Sometimes, a static message just isn't enough to capture their attention and draw them back into the action.\n",
    "\n",
    "Veo 2 on Vertex AI brings Google's state of the art video generation capabilities to application developers. It's capable of creating videos with astonishing detail that simulate real-world physics across a wide range of visual styles.\n",
    "\n",
    "In this lab we will explore how to leverage Veo 2 for video generation, powered by the creative writing process of Gemini to craft effective prompts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2dcd5-e989-427c-be49-3d3dff0fc73f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69e106c-3dec-4924-8d78-45c6d7119494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.display import HTML\n",
    "import IPython.display\n",
    "import google.auth\n",
    "import requests\n",
    "import json\n",
    "import uuid\n",
    "import base64\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import base64\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import logging\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt, before_sleep_log, retry_if_exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a951ca3-c95b-4518-9499-5a37400df07f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting parameters \n",
    "\n",
    "**!! IMPORTANT**: Set your biq query location, region, location and dataset name and verify the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "417b1421-fae8-4239-a909-53323f58c451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_id = dp-summit25pra-5501\n",
      "user = 768895414091-compute@developer.gserviceaccount.com\n",
      "location = us-central1\n",
      "dataset_name = datathon_ds_team3\n",
      "bucket_name = gs://dp-summit25pra-5501_datathon_ds_team3\n"
     ]
    }
   ],
   "source": [
    "bigquery_location = \"us\"\n",
    "region = \"us\"\n",
    "location = \"us-central1\"\n",
    "team_name    = \"\"\n",
    "dataset_name = \"datathon_ds_{}\".format(team_name)\n",
    "bucket_name  = \"gs://{}_{}\".format(project_id,dataset_name)\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the date and time as desired\n",
    "formatted_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "# Get some values using gcloud\n",
    "project_id = !(gcloud config get-value project)\n",
    "user = !(gcloud auth list --filter=status:ACTIVE --format=\"value(account)\")\n",
    "\n",
    "if len(project_id) != 1:\n",
    "  raise RuntimeError(f\"project_id is not set: {project_id}\")\n",
    "project_id = project_id[0]\n",
    "\n",
    "if len(user) != 1:\n",
    "  raise RuntimeError(f\"user is not set: {user}\")\n",
    "user = user[0]\n",
    "\n",
    "print(f\"project_id = {project_id}\")\n",
    "print(f\"user = {user}\")\n",
    "print(f\"location = {location}\")\n",
    "print(f\"dataset_name = {dataset_name}\")\n",
    "print(f\"bucket_name = {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cb444-ce52-428b-9240-82bc686a2cf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d0cf6-9d94-4777-a867-abb281d58c63",
   "metadata": {},
   "source": [
    "### RestAPIHelper: calls the Google Cloud REST API using the current users credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c2ac415-c5d3-411c-a8f7-0505a6081c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
    "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
    "\n",
    "  import requests\n",
    "  import google.auth\n",
    "  import json\n",
    "\n",
    "  # Get an access token based upon the current user\n",
    "  creds, project = google.auth.default()\n",
    "  auth_req = google.auth.transport.requests.Request()\n",
    "  creds.refresh(auth_req)\n",
    "  access_token=creds.token\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\" : \"application/json\",\n",
    "    \"Authorization\" : \"Bearer \" + access_token\n",
    "  }\n",
    "\n",
    "  if http_verb == \"GET\":\n",
    "    response = requests.get(url, headers=headers)\n",
    "  elif http_verb == \"POST\":\n",
    "    response = requests.post(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"PUT\":\n",
    "    response = requests.put(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"PATCH\":\n",
    "    response = requests.patch(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"DELETE\":\n",
    "    response = requests.delete(url, headers=headers)\n",
    "  else:\n",
    "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    return json.loads(response.content)\n",
    "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
    "  else:\n",
    "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
    "    raise RuntimeError(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7282fac-9ccf-4d75-bea6-998c257d9813",
   "metadata": {},
   "source": [
    "### RetryCondition (for retrying LLM calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3ec90d-bf16-4d57-92f7-970ce269c71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RetryCondition(error):\n",
    "  error_string = str(error)\n",
    "  print(error_string)\n",
    "\n",
    "  retry_errors = [\n",
    "      \"RESOURCE_EXHAUSTED\",\n",
    "      \"No content in candidate\",\n",
    "      # Add more error messages here as needed\n",
    "  ]\n",
    "\n",
    "  for retry_error in retry_errors:\n",
    "    if retry_error in error_string:\n",
    "      print(\"Retrying...\")\n",
    "      return True\n",
    "\n",
    "  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f8429-fd76-4942-a00a-e0f8b61e827e",
   "metadata": {},
   "source": [
    "### Gemini LLM (2.0-flash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3edcafe3-2896-464c-8cf4-6b74e26b95ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(10), retry=retry_if_exception(RetryCondition), before_sleep=before_sleep_log(logging.getLogger(), logging.INFO))\n",
    "def GeminiLLM(prompt, model = \"gemini-2.0-flash\", response_schema = None,\n",
    "                 temperature = 1, topP = 1, topK = 32):\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
    "  # model = \"gemini-2.0-flash\"\n",
    "\n",
    "  llm_response = None\n",
    "  if temperature < 0:\n",
    "    temperature = 0\n",
    "\n",
    "  creds, project = google.auth.default()\n",
    "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
    "  creds.refresh(auth_req)\n",
    "  access_token=creds.token\n",
    "\n",
    "  headers = {\n",
    "      \"Content-Type\" : \"application/json\",\n",
    "      \"Authorization\" : \"Bearer \" + access_token\n",
    "  }\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
    "\n",
    "  generation_config = {\n",
    "    \"temperature\": temperature,\n",
    "    \"topP\": topP,\n",
    "    \"maxOutputTokens\": 8192,\n",
    "    \"candidateCount\": 1,\n",
    "    \"responseMimeType\": \"application/json\",\n",
    "  }\n",
    "\n",
    "  # Add inthe response schema for when it is provided\n",
    "  if response_schema is not None:\n",
    "    generation_config[\"responseSchema\"] = response_schema\n",
    "\n",
    "  if model == \"gemini-2.0-flash\":\n",
    "    generation_config[\"topK\"] = topK\n",
    "\n",
    "  payload = {\n",
    "    \"contents\": {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": {\n",
    "          \"text\": prompt\n",
    "      },\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      **generation_config\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }\n",
    "\n",
    "  response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    try:\n",
    "      json_response = json.loads(response.content)\n",
    "    except Exception as error:\n",
    "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
    "\n",
    "    if \"candidates\" in json_response:\n",
    "      candidates = json_response[\"candidates\"]\n",
    "      if len(candidates) > 0:\n",
    "        candidate = candidates[0]\n",
    "        if \"content\" in candidate:\n",
    "          content = candidate[\"content\"]\n",
    "          if \"parts\" in content:\n",
    "            parts = content[\"parts\"]\n",
    "            if len(parts):\n",
    "              part = parts[0]\n",
    "              if \"text\" in part:\n",
    "                text = part[\"text\"]\n",
    "                llm_response = text\n",
    "              else:\n",
    "                raise RuntimeError(\"No text in part: {response.content}\")\n",
    "            else:\n",
    "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
    "          else:\n",
    "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
    "        else:\n",
    "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
    "      else:\n",
    "        raise RuntimeError(\"No candidates: {response.content}\")\n",
    "    else:\n",
    "      raise RuntimeError(\"No candidates: {response.content}\")\n",
    "\n",
    "    # Remove some typically response characters (if asking for a JSON reply)\n",
    "    llm_response = llm_response.replace(\"```json\",\"\")\n",
    "    llm_response = llm_response.replace(\"```\",\"\")\n",
    "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
    "\n",
    "    return llm_response\n",
    "\n",
    "  else:\n",
    "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388365a-15ea-472d-be85-02ca1ccb8648",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2954264e-8a35-4c28-8223-a6ea0094a84f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetUsers():\n",
    "  sql = f\"\"\"SELECT user_pseudo_id, cnt_post_score\n",
    "  FROM `{dataset_name}.cc_full_dataset_for_genai`\n",
    "  WHERE churned=1\n",
    "  ORDER BY user_pseudo_id\"\"\"\n",
    "\n",
    "  result_df = RunQuery(sql)\n",
    "  result_list = []\n",
    "\n",
    "  for index, row in result_df.iterrows():\n",
    "    result_list.append({\n",
    "        \"user_pseudo_id\": row['user_pseudo_id'],\n",
    "        \"cnt_post_score\": row['cnt_post_score']\n",
    "    })\n",
    "\n",
    "  return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb988579-aa07-4035-9b7c-efb54070ad57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RunQuery(sql):\n",
    "  import time\n",
    "  from google.cloud import bigquery\n",
    "  client = bigquery.Client()\n",
    "\n",
    "  if (sql.startswith(\"SELECT\") or sql.startswith(\"WITH\")):\n",
    "      df_result = client.query(sql).to_dataframe()\n",
    "      return df_result\n",
    "  else:\n",
    "    job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "\n",
    "    # Check on the progress by getting the job's updated state.\n",
    "    query_job = client.get_job(\n",
    "        query_job.job_id, location=query_job.location\n",
    "    )\n",
    "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
    "\n",
    "    while query_job.state != \"DONE\":\n",
    "      time.sleep(2)\n",
    "      query_job = client.get_job(\n",
    "          query_job.job_id, location=query_job.location\n",
    "          )\n",
    "      print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
    "\n",
    "    if query_job.error_result == None:\n",
    "      return True\n",
    "    else:\n",
    "      raise Exception(query_job.error_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7c37d5-c230-4601-b3f7-280ba4236014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This was generated by GenAI\n",
    "\n",
    "def copy_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
    "  \"\"\"Copies a file from a local drive to a GCS bucket.\n",
    "\n",
    "  Args:\n",
    "      local_file_path: The full path to the local file.\n",
    "      bucket_name: The name of the GCS bucket to upload to.\n",
    "      destination_blob_name: The desired name of the uploaded file in the bucket.\n",
    "\n",
    "  Returns:\n",
    "      None\n",
    "  \"\"\"\n",
    "\n",
    "  import os\n",
    "  from google.cloud import storage\n",
    "\n",
    "  # Ensure the file exists locally\n",
    "  if not os.path.exists(local_file_path):\n",
    "      raise FileNotFoundError(f\"Local file '{local_file_path}' not found.\")\n",
    "\n",
    "  # Create a storage client\n",
    "  storage_client = storage.Client()\n",
    "\n",
    "  # Get a reference to the bucket\n",
    "  bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "  # Create a blob object with the desired destination path\n",
    "  blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "  # Upload the file from the local filesystem\n",
    "  content_type = \"\"\n",
    "  if local_file_path.endswith(\".html\"):\n",
    "    content_type = \"text/html; charset=utf-8\"\n",
    "\n",
    "  if local_file_path.endswith(\".json\"):\n",
    "    content_type = \"application/json; charset=utf-8\"\n",
    "\n",
    "  if content_type == \"\":\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "  else:\n",
    "    blob.upload_from_filename(local_file_path, content_type = content_type)\n",
    "\n",
    "  print(f\"File '{local_file_path}' uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}.  Content-Type: {content_type}'.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d717a9-0a50-418a-939d-9cd7482eb6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt: python to delete a file even if it does not exist\n",
    "\n",
    "def delete_file(filename):\n",
    "  try:\n",
    "    os.remove(filename)\n",
    "    print(f\"File '{filename}' deleted successfully.\")\n",
    "  except FileNotFoundError:\n",
    "    print(f\"File '{filename}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3055a19f-a875-4de0-8584-1c8bd7855346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PrettyPrintJson(json_string):\n",
    "  json_object = json.loads(json_string)\n",
    "  json_formatted_str = json.dumps(json_object, indent=2)\n",
    "  # print(json_formatted_str)\n",
    "  return json_formatted_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b321b-15e5-4887-a100-5a6d7ef96054",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Teach the LLM how to write Veo 2 prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b68fb2c1-19a4-455e-93bd-d5523e3e4b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to tell the LLM how to write text-to-video prompts\n",
    "\n",
    "text_to_video_prompt_guide = \"\"\"\n",
    "Text-to-Video Prompt Writing Help:\n",
    "\n",
    "Here are some our best practices for text-to-video prompts:\n",
    "\n",
    "Detailed prompts = better videos:\n",
    "  - More details you add, the more control you’ll have over the video.\n",
    "  - A prompt should look like this: \"Camera dollies to show a close up of a desperate man in a green trench coat is making a call on a rotary style wall-phone, green neon light, movie scene.\"\n",
    "    - Here is a break down of elements need to create a text-to-video prompt using the above prompt as an example:\n",
    "      - \"Camera dollies to show\" = \"Camera Motion\"\n",
    "      - \"A close up of\" = \"Composition\"\n",
    "      - \"A desperate man in a green trench coat\" = \"Subject\"\n",
    "      - \"Is making a call\" = \"Action\"\n",
    "      - \"On a roary style wall-phone\" = \"Scene\"\n",
    "      - \"Green Neon light\" = \"Ambiance\"\n",
    "      - \"Movie Scene\" = \"Style\"\n",
    "\n",
    "Use the right keywords for better control:\n",
    "  - Here is a list of some keywords that work well with text-to-video, use these in your prompts to get the desired camera motion or style.\n",
    "  - Subject: Who or what is the main focus of the shot.  Example: \"happy woman in her 30s\".\n",
    "  - Scene: Where is the location of the shot. Example \"on a busy street, in space\".\n",
    "  - Action: What is the subject doing Examples: \"walking\", \"running\", \"turning head\".\n",
    "  - Camera Motion: What the camera is doing. Example: \"POV shot\", \"Aerial View\", \"Tracking Drone view\", \"Tracking Shot\".\n",
    "\n",
    "Example text-to-video prompt using the above keywords:\n",
    "  - Example text-to-video prompt: \"Tracking drone view of a man driving a red convertible car in Palm Springs, 1970s, warm sunlight, long shadows\"\n",
    "  - Example text-to-video prompt: \"A POV shot from a vintage car driving in the rain, Canada at night, cinematic\"\n",
    "\n",
    "Styles:\n",
    "   - Overall aesthetic. Consider using specific film style keywords.  Examples: \"horror film\", \"film noir, \"animated styles\", \"3D cartoon style render\".\n",
    "  - Example text-to-video prompt: \"Over the shoulder of a young woman in a car, 1970s, film grain, horror film, cinematic he Film noir style, man and woman walk on the street, mystery, cinematic, black and white\"\n",
    "  - Example text-to-video prompt: \"A cute creatures with snow leopard-like fur is walking in winter forest, 3D cartoon style render. An architectural rendering of a white concrete apartment building with flowing organic shapes, seamlessly blending with lush greenery and futuristic elements.\"\n",
    "\n",
    "Composition:\n",
    "  - How the shot is framed. This is often relative to the subject e.g. wide shot, close-up, low angle\n",
    "  - Example text-to-video prompt: \"Extreme close-up of a an eye with city reflected in it. A wide shot of surfer walking on a beach with a surfboard, beautiful sunset, cinematic\"\n",
    "\n",
    "Ambiance & Emotions:\n",
    "  - How the color and light contribute to the scene (blue tones, night)\n",
    "  - Example text-to-video prompt: \"A close-up of a girl holding adorable golden retriever puppy in the park, sunlight Cinematic close-up shot of a sad woman riding a bus in the rain, cool blue tones, sad mood\"\n",
    "\n",
    "Cinematic effects:\n",
    "  - e.g. double exposure, projected, glitch camera effect.\n",
    "  - Example text-to-video prompt: \"A double exposure of silhouetted profile of a woman walking and lake, walking in a forest Close-up shot of a model with blue light with geometric shapes projected on her face\"\n",
    "  - Example text-to-video prompt: \"Silhouette of a man walking in collage of cityscapes Glitch camera effect, close up of woman’s face speaking, neon colors\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0a5a1-bc43-4cb2-8573-1956a8187e9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Veo 2 Prompts using Gemini (let Gemini write the prompts for us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a03323-6ef2-4670-a32e-c51b941a1f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_to_video_prompts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5296e894-0f15-42e0-ae6d-ead4768c07db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 Not found: Dataset dp-summit25pra-5501:datathon_ds_team3 was not found in location US; reason: notFound, message: Not found: Dataset dp-summit25pra-5501:datathon_ds_team3 was not found in location US\n\nLocation: US\nJob ID: b24d6816-2d48-4e7c-ab98-248da58dff06\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m response_schema \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m   }\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 13\u001b[0m user_list \u001b[38;5;241m=\u001b[39m \u001b[43mGetUsers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m user_pseudo_id \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(user_list))\n\u001b[1;32m     15\u001b[0m cnt_post_score \u001b[38;5;241m=\u001b[39m user_list[user_pseudo_id\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnt_post_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mGetUsers\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mGetUsers\u001b[39m():\n\u001b[1;32m      2\u001b[0m   sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mSELECT user_pseudo_id, cnt_post_score\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m  FROM `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.cc_full_dataset_for_genai`\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m  WHERE churned=1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m  ORDER BY user_pseudo_id\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m   result_df \u001b[38;5;241m=\u001b[39m \u001b[43mRunQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m result_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mRunQuery\u001b[0;34m(sql)\u001b[0m\n\u001b[1;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (sql\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m sql\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWITH\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m----> 7\u001b[0m     df_result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_result\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2059\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   1830\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1831\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   1852\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m            :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2059\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[43mwait_for_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m   2061\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39mbqstorage_client,\n\u001b[1;32m   2062\u001b[0m         dtypes\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2076\u001b[0m         range_timestamp_dtype\u001b[38;5;241m=\u001b[39mrange_timestamp_dtype,\n\u001b[1;32m   2077\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_tqdm_helpers.py:107\u001b[0m, in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m    103\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m get_progress_bar(\n\u001b[1;32m    104\u001b[0m     progress_bar_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery is running\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_total, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1681\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[0;32m-> 1681\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_job_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1682\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1630\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.is_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_failed_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;66;03m# Only try to restart the query job if the job failed for\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m     \u001b[38;5;66;03m# a retriable reason. For example, don't restart the query\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;66;03m# into an exception that can be processed by the\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;66;03m# `job_retry` predicate.\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m     restart_query_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m job_failed_exception\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1632\u001b[0m     \u001b[38;5;66;03m# Make sure that the _query_results are cached so we\u001b[39;00m\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;66;03m# can return a complete RowIterator.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[38;5;66;03m# making any extra API calls if the previous loop\u001b[39;00m\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;66;03m# iteration fetched the finished job.\u001b[39;00m\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(\n\u001b[1;32m   1642\u001b[0m         retry\u001b[38;5;241m=\u001b[39mretry, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreload_query_results_kwargs\n\u001b[1;32m   1643\u001b[0m     )\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Not found: Dataset dp-summit25pra-5501:datathon_ds_team3 was not found in location US; reason: notFound, message: Not found: Dataset dp-summit25pra-5501:datathon_ds_team3 was not found in location US\n\nLocation: US\nJob ID: b24d6816-2d48-4e7c-ab98-248da58dff06\n"
     ]
    }
   ],
   "source": [
    "response_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"required\": [\n",
    "    \"text-to-video-prompt\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"text-to-video-prompt\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "user_list = GetUsers()\n",
    "user_pseudo_id = random.randint(1, len(user_list))\n",
    "cnt_post_score = user_list[user_pseudo_id-1][\"cnt_post_score\"]\n",
    "\n",
    "gemini_ad_prompt = f\"\"\"You are a marketing expert at gaming company and are creating cacthy video for churning gamers. \n",
    "Your user didn't engage with the game for 24h and want to encourage them to play more, and you want to motivate them to come back to play more by letting them know about their current score.\n",
    "The video should be funny message that will remind the user about the game they played.\n",
    "\n",
    "The video should be about the following user score:\n",
    "{user_pseudo_id}: {cnt_post_score}\n",
    "\n",
    "Output Fields:\n",
    "- \"text-to-video-prompt\":\n",
    " - Read the  \"Text-to-Video Prompt Writing Help\" to learn more about how to create good text-to-video prompts.\n",
    " - Make sure you include all the relevant best practices when creating the text-to-video prompt:\n",
    " - A detailed prompt for generating the video using text-to-video technology.\n",
    " - Include \"text overlays\" in the text-to-video prompt with a uplifting message saying that it seems like he forgot about the game.\n",
    " - Do not include children in the text-to-video prompt.\n",
    "\n",
    "{text_to_video_prompt_guide}\n",
    "\"\"\"\n",
    "\n",
    "#print(gemini_ad_prompt)\n",
    "llm_result = GeminiLLM(gemini_ad_prompt, response_schema=response_schema)\n",
    "gemini_ad_results_dict = json.loads(llm_result)\n",
    "orginal_ad_results_dict = gemini_ad_results_dict # in case we swap it for a pre-canned one\n",
    "print(f\"User Name: {user_pseudo_id} - {cnt_post_score}\")\n",
    "print()\n",
    "print(PrettyPrintJson(json.dumps(gemini_ad_results_dict)))\n",
    "text_to_video_prompts.append(gemini_ad_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23baf4b-f180-419f-a76e-af2d5b20940c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Video Generation using function generateVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e527c-dc0d-43bd-8580-49c45368d409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generateVideo(prompt, storage_account, output_gcs_path):\n",
    "  \"\"\"Calls text-to-video to create the video and waits for the output (which can be several minutes).  Saves the prompt/parameters with the vidoe.  Returns the outputted path.\"\"\"\n",
    "\n",
    "  full_output_gcs_path = f\"gs://{storage_account}/generated_videos\"\n",
    "  model = \"veo-2.0-generate-001\"\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1beta1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:predictLongRunning\"\n",
    "\n",
    "  request_body = {\n",
    "      \"instances\": [\n",
    "          {\n",
    "              \"prompt\": prompt\n",
    "          }\n",
    "        ],\n",
    "      \"parameters\": {\n",
    "          \"storageUri\": full_output_gcs_path,\n",
    "          \"aspectRatio\":\"16:9\"\n",
    "          }\n",
    "      }\n",
    "\n",
    "  rest_api_parameters = request_body.copy()\n",
    "\n",
    "  print(f\"url: {url}\")\n",
    "  print(f\"request_body: {request_body}\")\n",
    "  json_result = restAPIHelper(url, \"POST\", request_body)\n",
    "  print(f\"json_result: {json_result}\")\n",
    "  operation_name = json_result[\"name\"] # odd this is name\n",
    "\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1beta1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:fetchPredictOperation\"\n",
    "\n",
    "  request_body = {\n",
    "      \"operationName\": operation_name\n",
    "      }\n",
    "\n",
    "  status = False\n",
    "\n",
    "  while status == False:\n",
    "    time.sleep(10)\n",
    "    print(f\"url: {url}\")\n",
    "    print(f\"request_body: {request_body}\")\n",
    "    json_result = restAPIHelper(url, \"POST\", request_body)\n",
    "    print(f\"json_result: {json_result}\")\n",
    "    if \"done\" in json_result:\n",
    "      status = bool(json_result[\"done\"]) # in the future might be a status of running\n",
    "    else:\n",
    "      print(\"Status 'done' JSON attribute not present.  Assuming not done...\")\n",
    "\n",
    "  # Get the filename of our video\n",
    "  filename = json_result[\"response\"][\"videos\"][0][\"gcsUri\"]\n",
    "\n",
    "  # Save our prompt (this was we know what we used to generate the video)\n",
    "  json_filename = \"text-to-video-prompt.json\"\n",
    "  with open(json_filename, \"w\") as f:\n",
    "    f.write(json.dumps(rest_api_parameters))\n",
    "\n",
    "  # get the random number directory from text-to-video\n",
    "  text_to_video_output_directory = filename.replace(full_output_gcs_path,\"\")\n",
    "  text_to_video_output_directory = text_to_video_output_directory.split(\"/\")[1]\n",
    "  text_to_video_output_directory\n",
    "\n",
    "  # Write the prompt to the same path as our outputted video.  Saving the prompt allow us to know how to regenerate it (you should also save the seed and any other settings)\n",
    "  copy_file_to_gcs(json_filename, storage_account, f\"{output_gcs_path}/{text_to_video_output_directory}/{json_filename}\")\n",
    "  delete_file(json_filename)\n",
    "\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d10d0-6843-4284-9b3b-d516724fb1b9",
   "metadata": {},
   "source": [
    "### Create google cloud storage bucket to store your generated prompt and videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb070319-b4b7-4a66-b95e-562d0cc7ba6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://dp-summit25pra-5501_datathon_ds_team3/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb -p $project_id -l US-CENTRAL1 {bucket_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9573b-a60f-482b-9fbd-f2a9ab95e183",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Call Veo2 API with Gemini generated prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709dbb05-e303-41ab-880f-0a8022b7d452",
   "metadata": {},
   "source": [
    "!! IMPORTANT: Copy the above generated prompt, and your bucket name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927d33e-92c4-4402-b369-a68e9fee257d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_file_uri = generateVideo(\n",
    "    prompt=\"<YOUR_PROMPT>\",\n",
    "    storage_account=\"YOUR_BUCKET_NAME\",\n",
    "    output_gcs_path=f\"gs://{storage_account}/generated_videos\"\n",
    ")\n",
    "\n",
    "if video_file_uri:\n",
    "    print(f\"Video generation started, final URI will be: {video_file_uri}\")\n",
    "else:\n",
    "    print(\"Video generation call failed or returned no URI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f4da4-d89d-432b-84a7-1cfe6a647473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
