{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628bb0c7-dad9-4d32-954f-275f6c64380b",
   "metadata": {},
   "source": [
    "# **LAB_6 Veo2 for text-to-video**\n",
    "\n",
    "\n",
    "Are your users receiving your messages but still not returning to your game? Sometimes, a static message just isn't enough to capture their attention and draw them back into the action.\n",
    "\n",
    "Veo 2 on Vertex AI brings Google's state of the art video generation capabilities to application developers. It's capable of creating videos with astonishing detail that simulate real-world physics across a wide range of visual styles.\n",
    "\n",
    "In this lab we will explore how to leverage Veo 2 for video generation, powered by the creative writing process of Gemini to craft effective prompts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2dcd5-e989-427c-be49-3d3dff0fc73f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e106c-3dec-4924-8d78-45c6d7119494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.display import HTML\n",
    "import IPython.display\n",
    "import google.auth\n",
    "import requests\n",
    "import json\n",
    "import uuid\n",
    "import base64\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import base64\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import logging\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt, before_sleep_log, retry_if_exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a951ca3-c95b-4518-9499-5a37400df07f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting parameters \n",
    "\n",
    "**!! IMPORTANT**: Set your location and dataset name and verify the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b1421-fae8-4239-a909-53323f58c451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bigquery_location = \"us\"\n",
    "region = \"us\"\n",
    "location = \"us-central1\"\n",
    "team_name    = \"\"\n",
    "dataset_name = \"datathon_ds_{}\".format(team_name)\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the date and time as desired\n",
    "formatted_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "# Get some values using gcloud\n",
    "project_id = !(gcloud config get-value project)\n",
    "user = !(gcloud auth list --filter=status:ACTIVE --format=\"value(account)\")\n",
    "\n",
    "if len(project_id) != 1:\n",
    "  raise RuntimeError(f\"project_id is not set: {project_id}\")\n",
    "project_id = project_id[0]\n",
    "\n",
    "if len(user) != 1:\n",
    "  raise RuntimeError(f\"user is not set: {user}\")\n",
    "user = user[0]\n",
    "\n",
    "print(f\"project_id = {project_id}\")\n",
    "print(f\"user = {user}\")\n",
    "print(f\"location = {location}\")\n",
    "print(f\"dataset_name = {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cb444-ce52-428b-9240-82bc686a2cf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d0cf6-9d94-4777-a867-abb281d58c63",
   "metadata": {},
   "source": [
    "### RestAPIHelper: calls the Google Cloud REST API using the current users credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ac415-c5d3-411c-a8f7-0505a6081c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
    "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
    "\n",
    "  import requests\n",
    "  import google.auth\n",
    "  import json\n",
    "\n",
    "  # Get an access token based upon the current user\n",
    "  creds, project = google.auth.default()\n",
    "  auth_req = google.auth.transport.requests.Request()\n",
    "  creds.refresh(auth_req)\n",
    "  access_token=creds.token\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\" : \"application/json\",\n",
    "    \"Authorization\" : \"Bearer \" + access_token\n",
    "  }\n",
    "\n",
    "  if http_verb == \"GET\":\n",
    "    response = requests.get(url, headers=headers)\n",
    "  elif http_verb == \"POST\":\n",
    "    response = requests.post(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"PUT\":\n",
    "    response = requests.put(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"PATCH\":\n",
    "    response = requests.patch(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"DELETE\":\n",
    "    response = requests.delete(url, headers=headers)\n",
    "  else:\n",
    "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    return json.loads(response.content)\n",
    "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
    "  else:\n",
    "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
    "    raise RuntimeError(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7282fac-9ccf-4d75-bea6-998c257d9813",
   "metadata": {},
   "source": [
    "### RetryCondition (for retrying LLM calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ec90d-bf16-4d57-92f7-970ce269c71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RetryCondition(error):\n",
    "  error_string = str(error)\n",
    "  print(error_string)\n",
    "\n",
    "  retry_errors = [\n",
    "      \"RESOURCE_EXHAUSTED\",\n",
    "      \"No content in candidate\",\n",
    "      # Add more error messages here as needed\n",
    "  ]\n",
    "\n",
    "  for retry_error in retry_errors:\n",
    "    if retry_error in error_string:\n",
    "      print(\"Retrying...\")\n",
    "      return True\n",
    "\n",
    "  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f8429-fd76-4942-a00a-e0f8b61e827e",
   "metadata": {},
   "source": [
    "### Gemini LLM (2.0-flash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edcafe3-2896-464c-8cf4-6b74e26b95ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(10), retry=retry_if_exception(RetryCondition), before_sleep=before_sleep_log(logging.getLogger(), logging.INFO))\n",
    "def GeminiLLM(prompt, model = \"gemini-2.0-flash\", response_schema = None,\n",
    "                 temperature = 1, topP = 1, topK = 32):\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
    "  # model = \"gemini-2.0-flash\"\n",
    "\n",
    "  llm_response = None\n",
    "  if temperature < 0:\n",
    "    temperature = 0\n",
    "\n",
    "  creds, project = google.auth.default()\n",
    "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
    "  creds.refresh(auth_req)\n",
    "  access_token=creds.token\n",
    "\n",
    "  headers = {\n",
    "      \"Content-Type\" : \"application/json\",\n",
    "      \"Authorization\" : \"Bearer \" + access_token\n",
    "  }\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
    "\n",
    "  generation_config = {\n",
    "    \"temperature\": temperature,\n",
    "    \"topP\": topP,\n",
    "    \"maxOutputTokens\": 8192,\n",
    "    \"candidateCount\": 1,\n",
    "    \"responseMimeType\": \"application/json\",\n",
    "  }\n",
    "\n",
    "  # Add inthe response schema for when it is provided\n",
    "  if response_schema is not None:\n",
    "    generation_config[\"responseSchema\"] = response_schema\n",
    "\n",
    "  if model == \"gemini-2.0-flash\":\n",
    "    generation_config[\"topK\"] = topK\n",
    "\n",
    "  payload = {\n",
    "    \"contents\": {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": {\n",
    "          \"text\": prompt\n",
    "      },\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      **generation_config\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }\n",
    "\n",
    "  response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    try:\n",
    "      json_response = json.loads(response.content)\n",
    "    except Exception as error:\n",
    "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
    "\n",
    "    if \"candidates\" in json_response:\n",
    "      candidates = json_response[\"candidates\"]\n",
    "      if len(candidates) > 0:\n",
    "        candidate = candidates[0]\n",
    "        if \"content\" in candidate:\n",
    "          content = candidate[\"content\"]\n",
    "          if \"parts\" in content:\n",
    "            parts = content[\"parts\"]\n",
    "            if len(parts):\n",
    "              part = parts[0]\n",
    "              if \"text\" in part:\n",
    "                text = part[\"text\"]\n",
    "                llm_response = text\n",
    "              else:\n",
    "                raise RuntimeError(\"No text in part: {response.content}\")\n",
    "            else:\n",
    "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
    "          else:\n",
    "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
    "        else:\n",
    "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
    "      else:\n",
    "        raise RuntimeError(\"No candidates: {response.content}\")\n",
    "    else:\n",
    "      raise RuntimeError(\"No candidates: {response.content}\")\n",
    "\n",
    "    # Remove some typically response characters (if asking for a JSON reply)\n",
    "    llm_response = llm_response.replace(\"```json\",\"\")\n",
    "    llm_response = llm_response.replace(\"```\",\"\")\n",
    "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
    "\n",
    "    return llm_response\n",
    "\n",
    "  else:\n",
    "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388365a-15ea-472d-be85-02ca1ccb8648",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954264e-8a35-4c28-8223-a6ea0094a84f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetUsers():\n",
    "  sql = f\"\"\"SELECT user_pseudo_id, cnt_post_score\n",
    "  FROM `{dataset_name}.cc_full_dataset_for_genai`\n",
    "  WHERE churned=1\n",
    "  ORDER BY user_pseudo_id\"\"\"\n",
    "\n",
    "  result_df = RunQuery(sql)\n",
    "  result_list = []\n",
    "\n",
    "  for index, row in result_df.iterrows():\n",
    "    result_list.append({\n",
    "        \"user_pseudo_id\": row['user_pseudo_id'],\n",
    "        \"cnt_post_score\": row['cnt_post_score']\n",
    "    })\n",
    "\n",
    "  return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb988579-aa07-4035-9b7c-efb54070ad57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RunQuery(sql):\n",
    "  import time\n",
    "  from google.cloud import bigquery\n",
    "  client = bigquery.Client()\n",
    "\n",
    "  if (sql.startswith(\"SELECT\") or sql.startswith(\"WITH\")):\n",
    "      df_result = client.query(sql).to_dataframe()\n",
    "      return df_result\n",
    "  else:\n",
    "    job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "\n",
    "    # Check on the progress by getting the job's updated state.\n",
    "    query_job = client.get_job(\n",
    "        query_job.job_id, location=query_job.location\n",
    "    )\n",
    "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
    "\n",
    "    while query_job.state != \"DONE\":\n",
    "      time.sleep(2)\n",
    "      query_job = client.get_job(\n",
    "          query_job.job_id, location=query_job.location\n",
    "          )\n",
    "      print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
    "\n",
    "    if query_job.error_result == None:\n",
    "      return True\n",
    "    else:\n",
    "      raise Exception(query_job.error_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c37d5-c230-4601-b3f7-280ba4236014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This was generated by GenAI\n",
    "\n",
    "def copy_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
    "  \"\"\"Copies a file from a local drive to a GCS bucket.\n",
    "\n",
    "  Args:\n",
    "      local_file_path: The full path to the local file.\n",
    "      bucket_name: The name of the GCS bucket to upload to.\n",
    "      destination_blob_name: The desired name of the uploaded file in the bucket.\n",
    "\n",
    "  Returns:\n",
    "      None\n",
    "  \"\"\"\n",
    "\n",
    "  import os\n",
    "  from google.cloud import storage\n",
    "\n",
    "  # Ensure the file exists locally\n",
    "  if not os.path.exists(local_file_path):\n",
    "      raise FileNotFoundError(f\"Local file '{local_file_path}' not found.\")\n",
    "\n",
    "  # Create a storage client\n",
    "  storage_client = storage.Client()\n",
    "\n",
    "  # Get a reference to the bucket\n",
    "  bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "  # Create a blob object with the desired destination path\n",
    "  blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "  # Upload the file from the local filesystem\n",
    "  content_type = \"\"\n",
    "  if local_file_path.endswith(\".html\"):\n",
    "    content_type = \"text/html; charset=utf-8\"\n",
    "\n",
    "  if local_file_path.endswith(\".json\"):\n",
    "    content_type = \"application/json; charset=utf-8\"\n",
    "\n",
    "  if content_type == \"\":\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "  else:\n",
    "    blob.upload_from_filename(local_file_path, content_type = content_type)\n",
    "\n",
    "  print(f\"File '{local_file_path}' uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}.  Content-Type: {content_type}'.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d717a9-0a50-418a-939d-9cd7482eb6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt: python to delete a file even if it does not exist\n",
    "\n",
    "def delete_file(filename):\n",
    "  try:\n",
    "    os.remove(filename)\n",
    "    print(f\"File '{filename}' deleted successfully.\")\n",
    "  except FileNotFoundError:\n",
    "    print(f\"File '{filename}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3055a19f-a875-4de0-8584-1c8bd7855346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PrettyPrintJson(json_string):\n",
    "  json_object = json.loads(json_string)\n",
    "  json_formatted_str = json.dumps(json_object, indent=2)\n",
    "  # print(json_formatted_str)\n",
    "  return json_formatted_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b321b-15e5-4887-a100-5a6d7ef96054",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Teach the LLM how to write Veo 2 prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68fb2c1-19a4-455e-93bd-d5523e3e4b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to tell the LLM how to write text-to-video prompts\n",
    "\n",
    "text_to_video_prompt_guide = \"\"\"\n",
    "Text-to-Video Prompt Writing Help:\n",
    "\n",
    "Here are some our best practices for text-to-video prompts:\n",
    "\n",
    "Detailed prompts = better videos:\n",
    "  - More details you add, the more control you’ll have over the video.\n",
    "  - A prompt should look like this: \"Camera dollies to show a close up of a desperate man in a green trench coat is making a call on a rotary style wall-phone, green neon light, movie scene.\"\n",
    "    - Here is a break down of elements need to create a text-to-video prompt using the above prompt as an example:\n",
    "      - \"Camera dollies to show\" = \"Camera Motion\"\n",
    "      - \"A close up of\" = \"Composition\"\n",
    "      - \"A desperate man in a green trench coat\" = \"Subject\"\n",
    "      - \"Is making a call\" = \"Action\"\n",
    "      - \"On a roary style wall-phone\" = \"Scene\"\n",
    "      - \"Green Neon light\" = \"Ambiance\"\n",
    "      - \"Movie Scene\" = \"Style\"\n",
    "\n",
    "Use the right keywords for better control:\n",
    "  - Here is a list of some keywords that work well with text-to-video, use these in your prompts to get the desired camera motion or style.\n",
    "  - Subject: Who or what is the main focus of the shot.  Example: \"happy woman in her 30s\".\n",
    "  - Scene: Where is the location of the shot. Example \"on a busy street, in space\".\n",
    "  - Action: What is the subject doing Examples: \"walking\", \"running\", \"turning head\".\n",
    "  - Camera Motion: What the camera is doing. Example: \"POV shot\", \"Aerial View\", \"Tracking Drone view\", \"Tracking Shot\".\n",
    "\n",
    "Example text-to-video prompt using the above keywords:\n",
    "  - Example text-to-video prompt: \"Tracking drone view of a man driving a red convertible car in Palm Springs, 1970s, warm sunlight, long shadows\"\n",
    "  - Example text-to-video prompt: \"A POV shot from a vintage car driving in the rain, Canada at night, cinematic\"\n",
    "\n",
    "Styles:\n",
    "   - Overall aesthetic. Consider using specific film style keywords.  Examples: \"horror film\", \"film noir, \"animated styles\", \"3D cartoon style render\".\n",
    "  - Example text-to-video prompt: \"Over the shoulder of a young woman in a car, 1970s, film grain, horror film, cinematic he Film noir style, man and woman walk on the street, mystery, cinematic, black and white\"\n",
    "  - Example text-to-video prompt: \"A cute creatures with snow leopard-like fur is walking in winter forest, 3D cartoon style render. An architectural rendering of a white concrete apartment building with flowing organic shapes, seamlessly blending with lush greenery and futuristic elements.\"\n",
    "\n",
    "Composition:\n",
    "  - How the shot is framed. This is often relative to the subject e.g. wide shot, close-up, low angle\n",
    "  - Example text-to-video prompt: \"Extreme close-up of a an eye with city reflected in it. A wide shot of surfer walking on a beach with a surfboard, beautiful sunset, cinematic\"\n",
    "\n",
    "Ambiance & Emotions:\n",
    "  - How the color and light contribute to the scene (blue tones, night)\n",
    "  - Example text-to-video prompt: \"A close-up of a girl holding adorable golden retriever puppy in the park, sunlight Cinematic close-up shot of a sad woman riding a bus in the rain, cool blue tones, sad mood\"\n",
    "\n",
    "Cinematic effects:\n",
    "  - e.g. double exposure, projected, glitch camera effect.\n",
    "  - Example text-to-video prompt: \"A double exposure of silhouetted profile of a woman walking and lake, walking in a forest Close-up shot of a model with blue light with geometric shapes projected on her face\"\n",
    "  - Example text-to-video prompt: \"Silhouette of a man walking in collage of cityscapes Glitch camera effect, close up of woman’s face speaking, neon colors\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0a5a1-bc43-4cb2-8573-1956a8187e9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Veo 2 Prompts using Gemini (let Gemini write the prompts for us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a03323-6ef2-4670-a32e-c51b941a1f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_to_video_prompts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296e894-0f15-42e0-ae6d-ead4768c07db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"required\": [\n",
    "    \"text-to-video-prompt\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"text-to-video-prompt\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "user_list = GetUsers()\n",
    "user_pseudo_id = random.randint(1, len(user_list))\n",
    "cnt_post_score = user_list[user_pseudo_id-1][\"cnt_post_score\"]\n",
    "\n",
    "gemini_ad_prompt = f\"\"\"You are a marketing expert at gaming company and are creating cacthy video for churning gamers. \n",
    "Your user didn't engage with the game for 24h and want to encourage them to play more, and you want to motivate them to come back to play more by letting them know about their current score.\n",
    "The video should be funny message that will remind the user about the game they played.\n",
    "\n",
    "The video should be about the following user score:\n",
    "{user_pseudo_id}: {cnt_post_score}\n",
    "\n",
    "Output Fields:\n",
    "- \"text-to-video-prompt\":\n",
    " - Read the  \"Text-to-Video Prompt Writing Help\" to learn more about how to create good text-to-video prompts.\n",
    " - Make sure you include all the relevant best practices when creating the text-to-video prompt:\n",
    " - A detailed prompt for generating the video using text-to-video technology.\n",
    " - Include \"text overlays\" in the text-to-video prompt with a uplifting message saying that it seems like he forgot about the game.\n",
    " - Do not include children in the text-to-video prompt.\n",
    "\n",
    "{text_to_video_prompt_guide}\n",
    "\"\"\"\n",
    "\n",
    "#print(gemini_ad_prompt)\n",
    "llm_result = GeminiLLM(gemini_ad_prompt, response_schema=response_schema)\n",
    "gemini_ad_results_dict = json.loads(llm_result)\n",
    "orginal_ad_results_dict = gemini_ad_results_dict # in case we swap it for a pre-canned one\n",
    "print(f\"User Name: {user_pseudo_id} - {cnt_post_score}\")\n",
    "print()\n",
    "print(PrettyPrintJson(json.dumps(gemini_ad_results_dict)))\n",
    "text_to_video_prompts.append(gemini_ad_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23baf4b-f180-419f-a76e-af2d5b20940c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Video Generation using function generateVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e527c-dc0d-43bd-8580-49c45368d409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generateVideo(prompt, storage_account, output_gcs_path):\n",
    "  \"\"\"Calls text-to-video to create the video and waits for the output (which can be several minutes).  Saves the prompt/parameters with the vidoe.  Returns the outputted path.\"\"\"\n",
    "\n",
    "  full_output_gcs_path = f\"gs://{storage_account}/generated_videos\"\n",
    "  model = \"veo-2.0-generate-001\"\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1beta1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:predictLongRunning\"\n",
    "\n",
    "  request_body = {\n",
    "      \"instances\": [\n",
    "          {\n",
    "              \"prompt\": prompt\n",
    "          }\n",
    "        ],\n",
    "      \"parameters\": {\n",
    "          \"storageUri\": full_output_gcs_path,\n",
    "          \"aspectRatio\":\"16:9\"\n",
    "          }\n",
    "      }\n",
    "\n",
    "  rest_api_parameters = request_body.copy()\n",
    "\n",
    "  print(f\"url: {url}\")\n",
    "  print(f\"request_body: {request_body}\")\n",
    "  json_result = restAPIHelper(url, \"POST\", request_body)\n",
    "  print(f\"json_result: {json_result}\")\n",
    "  operation_name = json_result[\"name\"] # odd this is name\n",
    "\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1beta1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:fetchPredictOperation\"\n",
    "\n",
    "  request_body = {\n",
    "      \"operationName\": operation_name\n",
    "      }\n",
    "\n",
    "  status = False\n",
    "\n",
    "  while status == False:\n",
    "    time.sleep(10)\n",
    "    print(f\"url: {url}\")\n",
    "    print(f\"request_body: {request_body}\")\n",
    "    json_result = restAPIHelper(url, \"POST\", request_body)\n",
    "    print(f\"json_result: {json_result}\")\n",
    "    if \"done\" in json_result:\n",
    "      status = bool(json_result[\"done\"]) # in the future might be a status of running\n",
    "    else:\n",
    "      print(\"Status 'done' JSON attribute not present.  Assuming not done...\")\n",
    "\n",
    "  # Get the filename of our video\n",
    "  filename = json_result[\"response\"][\"videos\"][0][\"gcsUri\"]\n",
    "\n",
    "  # Save our prompt (this was we know what we used to generate the video)\n",
    "  json_filename = \"text-to-video-prompt.json\"\n",
    "  with open(json_filename, \"w\") as f:\n",
    "    f.write(json.dumps(rest_api_parameters))\n",
    "\n",
    "  # get the random number directory from text-to-video\n",
    "  text_to_video_output_directory = filename.replace(full_output_gcs_path,\"\")\n",
    "  text_to_video_output_directory = text_to_video_output_directory.split(\"/\")[1]\n",
    "  text_to_video_output_directory\n",
    "\n",
    "  # Write the prompt to the same path as our outputted video.  Saving the prompt allow us to know how to regenerate it (you should also save the seed and any other settings)\n",
    "  copy_file_to_gcs(json_filename, storage_account, f\"{output_gcs_path}/{text_to_video_output_directory}/{json_filename}\")\n",
    "  delete_file(json_filename)\n",
    "\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d10d0-6843-4284-9b3b-d516724fb1b9",
   "metadata": {},
   "source": [
    "### Create google cloud storage bucket to store your generated prompt and videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb070319-b4b7-4a66-b95e-562d0cc7ba6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gsutil mb -p $project_id -l US-CENTRAL1 gs://<YOUR_BUCKET_NAME>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9573b-a60f-482b-9fbd-f2a9ab95e183",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Call Veo2 API with Gemini generated prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709dbb05-e303-41ab-880f-0a8022b7d452",
   "metadata": {},
   "source": [
    "!! IMPORTANT: Copy the above generated prompt, and your bucket name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927d33e-92c4-4402-b369-a68e9fee257d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_file_uri = generateVideo(\n",
    "    prompt=\"<YOUR_PROMPT>\",\n",
    "    storage_account=\"<YOUR_BUCKET_NAME>\",\n",
    "    output_gcs_path=f\"gs://{storage_account}/generated_videos\"\n",
    ")\n",
    "\n",
    "if video_file_uri:\n",
    "    print(f\"Video generation started, final URI will be: {video_file_uri}\")\n",
    "else:\n",
    "    print(\"Video generation call failed or returned no URI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f4da4-d89d-432b-84a7-1cfe6a647473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
